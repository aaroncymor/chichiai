import os
from contextlib import redirect_stdout
import io
import time
import warnings

import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.prompts.chat import SystemMessage, AIMessage, HumanMessagePromptTemplate

from chichiai.roles import TaskMaster
from chichiai.settings import OPENAI_API_KEY
# from chichiai.prompts import (
#     EXAMPLE_OUTPUT_DF, SYSTEM_TASK_EVALUATION, ANALYST_TASK_EVALUATION_DF,
#     SYSTEM_TASK_DF, USER_TASK_DF
# )
from chichiai.exceptions import EnvironmentError, UnsupportedModelError
from chichiai.utils import _extract_code

warnings.filterwarnings('ignore')

SUPPORTED_MODELS = {}

SUPPORTED_CHAT_MODELS = {
    'gpt-3.5-turbo-0613',
    'gpt-3.5-turbo-16k',
    'gpt-4-0613',
}


class ChiChiAI(object):
    """"""

    def __init__(self,
                 df: pd.DataFrame = None,
                 llm: str = "gpt-4-0613",
                 max_conversations: int = 4,
                 exploratory: bool = True,
                 search_tool: bool = False):

        # Dataframe
        self.df = df if df is not None else None

        # chat model only supported at the moment
        all_supported_models = SUPPORTED_CHAT_MODELS
        if SUPPORTED_MODELS:
            all_supported_models.update(SUPPORTED_MODELS)

        if llm not in all_supported_models:
            raise UnsupportedModelError(llm)

        if not OPENAI_API_KEY:
            raise EnvironmentError((
                "Error: Environment variable OPENAI_API_KEY is not set"))

        if llm in SUPPORTED_CHAT_MODELS:
            # use chat completion
            self.llm = ChatOpenAI(
                temperature=0,
                openai_api_key=OPENAI_API_KEY,
                model=llm
            )

        self.task_master = TaskMaster(self.llm, self.df, search_tool)

        self.max_error_corrections = 5
        self.max_conversations = max_conversations

    def pd_csv_agent_converse(self, question: str = None) -> str:
        tasks = self.task_master.evaluate_task(question)
        # print("Tasks", tasks)
        # print("pre_eval_messages", self.task_master.pre_eval_messages)
        # print("select_analyst_messages", self.task_master.select_analyst_messages)
        # print("eval_messages", self.task_master.eval_messages)
        # print("code_messages", self.task_master.code_messages)

        # update:
        # tasks already generated by instantiating TaskMaster class
        # and calling method `evaluate_tasks` that returns list of tasks for
        # assisting in generating code

        # next steps 1: implement generate_code, extract_code, and execute_code
        # next steps 2: look into memory and how to apply this with the TaskMaster
        # https://sonery.medium.com/the-memory-component-of-langchain-for-chatgpt-conversations-8f42a4e9db5b
        # https://sonery.medium.com/4-memory-types-of-langchain-to-enhance-the-performance-of-llms-bda339d2e904
        # https://python.langchain.com/docs/modules/memory/adding_memory
        # https://www.youtube.com/watch?v=dxO6pzlgJiY
